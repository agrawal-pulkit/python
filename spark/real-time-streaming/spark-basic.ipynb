{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName=\"Pi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = sc.textFile(\"students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name, Marks', 'Pulkit, 99', 'Aman, 100', 'Jhon, 89', 'Jerry, 78', 'Rob, 69']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterStudents = students.filter(lambda row : 'a' in row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name, Marks', 'Aman, 100']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterStudents.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_file = os.path.join(os.path.pardir, \"real-time-streaming\", 'streaming-demo.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing $streaming_file\n"
     ]
    }
   ],
   "source": [
    "%%writefile $streaming_file\n",
    "\n",
    "import sys\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    sc = SparkContext(appName= \"StreamingData\")\n",
    "    ssc = StreamingContext(sc, 2)\n",
    "    \n",
    "    ssc.checkpoint(os.path.join(os.path.pardir, \"real-time-streaming\", 'tmp'))\n",
    "    \n",
    "    lines = ssc.socketTextStream(sys.argv[1], int(sys.argv[2]))\n",
    "    \n",
    "    counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "                    .filter(lambda word: \"ERROR\" in word)\\\n",
    "                    .map(lambda word: (word, 1))\\\n",
    "                    .reduceByKey(lambda a, b: a+b)\n",
    "    \n",
    "    counts.pprint()\n",
    "    \n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-submit streaming-demo.py localhost 9991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_streaming_file = os.path.join(os.path.pardir, \"real-time-streaming\", 'testtwitterstream-message.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../real-time-streaming/testtwitterstream-message.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $twitter_streaming_file\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler, Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "class TweetsListener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('Tweet Listener class initialized.')\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        print(\"on_data: {0}\".format(data))\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(\"error: {0}\".format(status))\n",
    "        return True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    api_key = \"05vmjOLTZazXj2doCsLYPXMgx\"\n",
    "    api_secret = \"OxV7iOFKA3x3nBBF9WHSpQ0w1SVcNdEjOt3GZPmFqDszahb31L\"\n",
    "    \n",
    "    access_token = \"1427298992-FNne49AJM0fnq6ZiHBB7RcjcxsslFwLD7Uj4Pnj\"\n",
    "    access_token_secret = \"7V4RDqhgxaemcb42mbBIY50T6eSYDesN6TzMcrxZKohww\"\n",
    "    \n",
    "    auth = OAuthHandler(api_key, api_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    \n",
    "    twitter_stream = Stream(auth, TweetsListener())\n",
    "    twitter_stream.filter(track=[\"#\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_streaming_live_file = os.path.join(os.path.pardir, \"real-time-streaming\", 'twitterstreaming.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../real-time-streaming/twitterstreaming.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $twitter_streaming_live_file\n",
    "\n",
    "import os\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    sc = SparkContext(appName= \"StreamingData\")\n",
    "    ssc = StreamingContext(sc, 2)\n",
    "    \n",
    "    ssc.checkpoint(os.path.join(os.path.pardir, \"real-time-streaming\", 'tmp'))\n",
    "    \n",
    "    lines = ssc.socketTextStream(\"localhost\", 7777)\n",
    "    \n",
    "    def count_words(newValues, lastSum):\n",
    "        if lastSum is None:\n",
    "            lastSum = 0\n",
    "        return sum(newValues, lastSum)\n",
    "    \n",
    "    words_counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "                    .filter(lambda word: \"ERROR\" in word)\\\n",
    "                    .map(lambda word: (word, 1))\\\n",
    "                    .updateStateByKey(count_words)\n",
    "    \n",
    "    words_counts.pprint()\n",
    "    \n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
